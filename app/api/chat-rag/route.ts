import { NextRequest, NextResponse } from "next/server"
import { OpenAI } from "openai"
import { createClient } from "@supabase/supabase-js"

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
})

const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE!
)

export async function POST(req: NextRequest) {
  try {
    console.log("‚úÖ Requ√™te re√ßue dans /api/chat-rag")

    const body = await req.json()
    const message = body.message?.trim()

    if (!message) {
      console.warn("‚ö†Ô∏è Message manquant")
      return NextResponse.json({ error: "Message manquant." }, { status: 400 })
    }

    console.log("üì® Message re√ßu :", message)

    // 1. Embedding
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: message,
    })

    const userEmbedding = embeddingResponse.data[0].embedding
    console.log("üî¢ Embedding g√©n√©r√©")

    // 2. Requ√™te Supabase
    const { data: matches, error } = await supabase.rpc("match_documents", {
      query_embedding: userEmbedding,
      match_threshold: 0.72,
      match_count: 10,
    })

    if (error) {
      console.error("‚ùå Erreur Supabase RPC :", error)
      return NextResponse.json({ error: "Erreur Supabase RPC" }, { status: 500 })
    }

    if (!matches || matches.length === 0) {
      console.log("üïµÔ∏è Aucun match trouv√©")
      return NextResponse.json({
        reply: "Je n‚Äôai pas assez d‚Äôinformations pour r√©pondre pr√©cis√©ment √† cette question sur mon parcours.",
      })
    }

    const context = matches.map((m: any) => m.content).join("\n---\n")
    console.log("üìÑ CONTEXTE TROUV√â :", context)

    // 3. Demande √† OpenAI avec contexte
    const completion = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        {
          role: "system",
          content: `
          Tu es Melchisedeck Mvita. Tu r√©ponds toujours √† la premi√®re personne en t‚Äôappuyant uniquement sur les informations suivantes (provenant de mon portfolio en ligne) :

          ${context}
          Ta r√©ponse doit refl√©ter mon **parcours professionnel**, mes **exp√©riences concr√®tes**, et **√©viter les g√©n√©ralit√©s**. Si certaines infos manquent, reformule avec ce que tu sais.`,

        },
        {
          role: "user",
          content: message,
        },
      ],
    })

    const reply = completion.choices?.[0]?.message?.content?.trim()

    if (!reply) {
      console.warn("‚ö†Ô∏è Pas de r√©ponse g√©n√©r√©e par OpenAI")
      return NextResponse.json({ error: "Pas de r√©ponse g√©n√©r√©e." }, { status: 500 })
    }

    console.log("ü§ñ R√©ponse g√©n√©r√©e :", reply)
    return NextResponse.json({ reply })
  } catch (err) {
    console.error("üí• Erreur serveur :", err)
    return NextResponse.json({ error: "Erreur interne serveur." }, { status: 500 })
  }
}
